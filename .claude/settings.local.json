{
  "permissions": {
    "allow": [
      "Bash(git status:*)",
      "Bash(git diff:*)",
      "Bash(git log:*)",
      "Bash(git branch:*)",
      "Bash(git checkout:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git push:*)",
      "Bash(git pull:*)",
      "Bash(git fetch:*)",
      "Bash(git stash:*)",
      "Bash(git show:*)",
      "Bash(git remote:*)",
      "Bash(cd:*)",
      "Bash(ls:*)",
      "Bash(pwd:*)",
      "Bash(mkdir:*)",
      "Bash(wc:*)",
      "Bash(head:*)",
      "Bash(tail:*)",
      "Bash(cat:*)",
      "Bash(dotnet build:*)",
      "Bash(dotnet test:*)",
      "Bash(dotnet restore:*)",
      "Bash(dotnet run:*)",
      "Bash(dotnet clean:*)",
      "Bash(dotnet --version:*)",
      "Bash(npm:*)",
      "Bash(node:*)",
      "Bash(which:*)",
      "Bash(where:*)",
      "Bash(echo:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nfix: optimize parser for large file support with element-by-element parsing\n\nAddresses critical performance issues preventing 200MB+ file imports:\n\nParser improvements \\(ChatGptConversationsJsonParser.cs\\):\n- Replace JsonDocument.ParseAsync with Utf8JsonReader + JsonDocument.ParseValue\n- Parse one conversation at a time instead of creating massive DOM for entire file\n- Memory: ~200MB bytes + ~100KB per conversation vs previous 800MB+ total\n\nPipeline improvements \\(IngestionPipeline.cs\\):\n- Add OpenArtifactStreamAsync\\(\\) to support file-based streaming via StoredPath\n- Falls back to RawJson for backwards compatibility\n- Enables streaming from filesystem for large artifacts\n\nTest updates \\(ChatGptParserPerformanceTests.cs\\):\n- Rename TimeToFirstYield test to document actual behavior\n- Adjust assertions to reflect element-by-element parsing performance\n\nAll 30 tests pass.\n\nðŸ¤– Generated with [Claude Code]\\(https://claude.com/claude-code\\)\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(dotnet ef migrations add:*)",
      "Bash(dotnet ef database update:*)"
    ]
  }
}
